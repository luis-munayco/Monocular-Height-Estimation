{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c936b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from functools import lru_cache\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "from multiprocessing import Pool\n",
    "from os import listdir\n",
    "from os.path import splitext, isfile, join\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_image(filename):\n",
    "    ext = splitext(filename)[1]\n",
    "    if ext == '.npy':\n",
    "        return Image.fromarray(np.load(filename))\n",
    "    elif ext in ['.pt', '.pth']:\n",
    "        return Image.fromarray(torch.load(filename).numpy())\n",
    "    else:\n",
    "        return Image.open(filename)\n",
    "\n",
    "idx=0\n",
    "mask_suffix='_AGL'\n",
    "img_suffix='_BAM'\n",
    "dir_img = Path('./data/imgs/')\n",
    "dir_mask = Path('./data/masks/')\n",
    "images_dir = Path(dir_img)\n",
    "mask_dir = Path(dir_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c8b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "262144\n",
      "(256, 256, 4)\n",
      "3\n",
      "65536\n",
      "(256, 256)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "ids = [splitext(file)[0].rsplit('_', 1)[0] for file in listdir(images_dir) if isfile(join(images_dir, file)) and not file.startswith('.')]\n",
    "if not ids:\n",
    "    raise RuntimeError(f'No input file found in {images_dir}, make sure you put your images there')\n",
    "\n",
    "name = ids[idx]\n",
    "mask_file = list(mask_dir.glob(name + mask_suffix + '.*'))\n",
    "img_file = list(images_dir.glob(name + img_suffix +  '.*'))\n",
    "\n",
    "assert len(img_file) == 1, f'Either no image or multiple images found for the ID {name}: {img_file}'\n",
    "assert len(mask_file) == 1, f'Either no mask or multiple masks found for the ID {name}: {mask_file}'\n",
    "\n",
    "\n",
    "print(len(img_file))\n",
    "print(len(mask_file))\n",
    "\n",
    "mask = load_image(mask_file[0])\n",
    "img = load_image(img_file[0])\n",
    "    \n",
    "assert img.size == mask.size, \\\n",
    "    f'Image and mask {name} should be the same size, but are {img.size} and {mask.size}'\n",
    "\n",
    "print(img.size)\n",
    "print(mask.size)\n",
    "\n",
    "img_ar = np.asarray(img)\n",
    "print(img_ar.size)\n",
    "print(img_ar.shape)\n",
    "print(img_ar.ndim)\n",
    "\n",
    "\n",
    "img_ar = np.asarray(mask)\n",
    "print(img_ar.size)\n",
    "print(img_ar.shape)\n",
    "print(img_ar.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d4321e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 74,  74,  67, ...,  80,  80,  74],\n",
       "        [ 64,  64,  60, ..., 103, 103,  94],\n",
       "        [ 48,  48,  51, ..., 119, 119, 115],\n",
       "        ...,\n",
       "        [ 42,  42,  34, ..., 107, 107, 113],\n",
       "        [ 57,  57,  49, ..., 139, 139, 130],\n",
       "        [ 74,  74,  72, ..., 167, 167, 142]],\n",
       "\n",
       "       [[ 73,  73,  68, ...,  73,  73,  70],\n",
       "        [ 65,  65,  63, ...,  92,  92,  87],\n",
       "        [ 55,  55,  56, ..., 106, 106, 104],\n",
       "        ...,\n",
       "        [ 45,  45,  36, ...,  98,  98, 104],\n",
       "        [ 55,  55,  48, ..., 124, 124, 119],\n",
       "        [ 68,  68,  65, ..., 147, 147, 128]],\n",
       "\n",
       "       [[ 45,  45,  41, ...,  46,  46,  45],\n",
       "        [ 39,  39,  35, ...,  65,  65,  63],\n",
       "        [ 28,  28,  29, ...,  77,  77,  77],\n",
       "        ...,\n",
       "        [ 24,  24,  17, ...,  72,  72,  80],\n",
       "        [ 32,  32,  25, ..., 100, 100,  94],\n",
       "        [ 44,  44,  39, ..., 120, 120, 100]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_trs=img_ar.transpose((2, 0, 1))\n",
    "img_trs[:3, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c43268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[2., 2., 2.],\n",
      "         [2., 2., 2.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[5., 5., 5.],\n",
      "         [5., 5., 5.],\n",
      "         [5., 5., 5.]]])\n",
      "target:  tensor([[[11, 11, 11],\n",
      "         [11, 11, 11],\n",
      "         [11, 11, 11]],\n",
      "\n",
      "        [[12, 12, 12],\n",
      "         [12, 12, 12],\n",
      "         [12, 12, 12]],\n",
      "\n",
      "        [[15, 15, 15],\n",
      "         [15, 15, 15],\n",
      "         [15, 15, 15]]])\n",
      "output:  tensor([[[10., 10., 10.],\n",
      "         [10., 10., 10.],\n",
      "         [10., 10., 10.]],\n",
      "\n",
      "        [[10., 10., 10.],\n",
      "         [10., 10., 10.],\n",
      "         [10., 10., 10.]],\n",
      "\n",
      "        [[10., 10., 10.],\n",
      "         [10., 10., 10.],\n",
      "         [10., 10., 10.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "input = torch.randn(3, 3)\n",
    "target = torch.randn(3, 3)\n",
    "\n",
    "# Create a batch tensor with tensors of 1s, 2s, and 5s\n",
    "batch_tensor1 = torch.stack([torch.ones((3, 3)), torch.full((3, 3), 2), torch.full((3, 3), 5)])\n",
    "\n",
    "# Create another batch tensor with tensors of 11s, 12s, and 15s\n",
    "batch_tensor2 = torch.stack([torch.full((3, 3), 11), torch.full((3, 3), 12), torch.full((3, 3), 15)])\n",
    "\n",
    "\n",
    "mae_loss = nn.L1Loss()\n",
    "output = F.l1_loss(batch_tensor1, batch_tensor2,reduction='none')\n",
    "#output.backward()\n",
    "\n",
    "print('input: ', batch_tensor1)\n",
    "print('target: ', batch_tensor2)\n",
    "print('output: ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10de68f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luism\\AppData\\Local\\Temp\\ipykernel_7660\\3658009299.py:20: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  pil_img = pil_img.resize((newW, newH), resample=Image.NEAREST if is_mask else Image.BICUBIC)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[187., 187., 175., ..., 159., 165., 164.],\n",
       "        [184., 184., 192., ..., 162., 168., 166.],\n",
       "        [184., 184., 192., ..., 162., 168., 166.],\n",
       "        ...,\n",
       "        [249., 249., 236., ..., 116., 113., 116.],\n",
       "        [250., 250., 231., ..., 118., 112., 116.],\n",
       "        [250., 250., 231., ..., 118., 112., 116.]],\n",
       "\n",
       "       [[163., 163., 155., ..., 132., 138., 138.],\n",
       "        [160., 160., 170., ..., 136., 140., 139.],\n",
       "        [160., 160., 170., ..., 136., 140., 139.],\n",
       "        ...,\n",
       "        [230., 230., 210., ...,  96.,  94.,  96.],\n",
       "        [227., 227., 204., ...,  96.,  92.,  96.],\n",
       "        [227., 227., 204., ...,  96.,  92.,  96.]],\n",
       "\n",
       "       [[132., 132., 125., ..., 104., 111., 112.],\n",
       "        [133., 133., 143., ..., 106., 112., 112.],\n",
       "        [133., 133., 143., ..., 106., 112., 112.],\n",
       "        ...,\n",
       "        [198., 198., 178., ...,  66.,  64.,  66.],\n",
       "        [191., 191., 169., ...,  67.,  62.,  65.],\n",
       "        [191., 191., 169., ...,  67.,  62.,  65.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import splitext, isfile, join\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def load_image(filename):\n",
    "    ext = splitext(filename)[1]\n",
    "    if ext == '.npy':\n",
    "        return Image.fromarray(np.load(filename))\n",
    "    elif ext in ['.pt', '.pth']:\n",
    "        return Image.fromarray(torch.load(filename).numpy())\n",
    "    else:\n",
    "        return Image.open(filename)\n",
    "    \n",
    "def preprocess(pil_img, scale, is_mask):\n",
    "        w, h = pil_img.size\n",
    "        newW, newH = int(scale * w), int(scale * h)\n",
    "        assert newW > 0 and newH > 0, 'Scale is too small, resized images would have no pixel'\n",
    "        pil_img = pil_img.resize((newW, newH), resample=Image.NEAREST if is_mask else Image.BICUBIC)\n",
    "        img = np.asarray(pil_img)\n",
    "\n",
    "        if is_mask:\n",
    "            mask=img[np.newaxis, :, :]\n",
    "            return mask\n",
    "\n",
    "        else:\n",
    "            if img.ndim == 2:\n",
    "                img = img[np.newaxis, ...]\n",
    "            else:\n",
    "                img = img.transpose((2, 0, 1))\n",
    "                img = img[:3, :, :]\n",
    "\n",
    "            if (img > 1).any():\n",
    "                img = img / 1\n",
    "\n",
    "            return img\n",
    "        \n",
    "img = load_image(Path('./data/imgs/BEL_01_05_4_4_BAM.tif'))\n",
    "img = preprocess(img, 1, is_mask=False)\n",
    "img\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
